{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitData-GA/shot-marilyns-analysis/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9D4brbMESGe"
      },
      "source": [
        "# Import libraries and scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oguePuOiAy3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17d7c25-9136-4520-bb06-3eae82f61cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'shot-marilyns-analysis'...\n",
            "remote: Enumerating objects: 1044, done.\u001b[K\n",
            "remote: Counting objects: 100% (331/331), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 1044 (delta 92), reused 271 (delta 82), pack-reused 713\u001b[K\n",
            "Receiving objects: 100% (1044/1044), 86.53 MiB | 10.49 MiB/s, done.\n",
            "Resolving deltas: 100% (309/309), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "!git clone https://github.com/GitData-GA/shot-marilyns-analysis.git\n",
        "sys.path.insert(0, './shot-marilyns-analysis/src')\n",
        "\n",
        "import sma\n",
        "os.makedirs(r'img')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySUTIX2bDXTF"
      },
      "source": [
        "# Improt images and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e_XdQCNBJbj"
      },
      "outputs": [],
      "source": [
        "img_links = {\n",
        "    \"orange_marilyn\": \"https://shotmarilyns.gd.edu.kg/assets/img/1_1_orange_marilyn.jpg\",\n",
        "    \"red_marilyn\": \"https://shotmarilyns.gd.edu.kg/assets/img/1_2_red_marilyn.jpg\",\n",
        "    \"turq_marilyn\": \"https://shotmarilyns.gd.edu.kg/assets/img/1_3_turq_marilyn.jpg\",\n",
        "    \"blue_marilyn\": \"https://shotmarilyns.gd.edu.kg/assets/img/1_4_blue_marilyn.jpg\",\n",
        "    \"eggblue_marilyn\": \"https://shotmarilyns.gd.edu.kg/assets/img/1_5_eggblue_marilyn.jpg\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpK5OYNuo77Y"
      },
      "source": [
        "## Save images to local directory and show them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTFMI8Xcn6UR"
      },
      "outputs": [],
      "source": [
        "sma.utils.save_img(img_links, img_idx=1, show_img=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vn31lmZWN8R"
      },
      "source": [
        "## Store the images as a NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrmAl_wPDZqM"
      },
      "outputs": [],
      "source": [
        "np_img = sma.utils.np_convert(img_links)\n",
        "np_img['orange_marilyn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TQbFyAUV2xs"
      },
      "source": [
        "## Store the images as a dictionary of 5 Pandas dataframes with HEX codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5F81926TRCs"
      },
      "outputs": [],
      "source": [
        "pd_img = sma.utils.pd_convert(img_links)\n",
        "pd_img['orange_marilyn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak4P8OdVkVqD"
      },
      "source": [
        "# Generating plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVajlTZwZxRa"
      },
      "source": [
        "## Distribution plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj2VdMsWuLu3"
      },
      "outputs": [],
      "source": [
        "sma.plot.distribution(np_img, img_idx=2, show_plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUApVeKDdBgJ"
      },
      "source": [
        "## Relative conditional entropy plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ihlb7qswxz4"
      },
      "outputs": [],
      "source": [
        "sma.plot.entropy_heatmap(np_img, img_idx=3, show_plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phgE3dP-cGxs"
      },
      "source": [
        "## RGB space scatterplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4SdH1h3P1qJJ"
      },
      "outputs": [],
      "source": [
        "sma.plot.scatter(pd_img, img_idx=4, show_plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbYxneMuWrah"
      },
      "source": [
        "## KMeans clustering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmean_result = sma.cluster.kmeans(pd_img, n_clusters=15)"
      ],
      "metadata": {
        "id": "ObFkRon4l3Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scatter plot by clusters"
      ],
      "metadata": {
        "id": "0H7SwbbixOvl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0A2vaeD7yP9"
      },
      "outputs": [],
      "source": [
        "sma.plot.scatter(pd_img, img_idx=5, kmeans=kmean_result, show_plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar chart by clusters"
      ],
      "metadata": {
        "id": "ekoZzJ6KxS-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sma.plot.bar(pd_img, img_idx=6, kmeans=kmean_result, show_plot=True)"
      ],
      "metadata": {
        "id": "cDe9bomqmsyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Color ribbon by clusters"
      ],
      "metadata": {
        "id": "rTB8V-sOxWAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sma.plot.ribbon(pd_img, img_idx=7, kmeans=kmean_result, show_plot=True)"
      ],
      "metadata": {
        "id": "9IW8QV_0osTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk_EgcwEgmQo"
      },
      "source": [
        "# Save all images in a zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrRr8euGyQ0z"
      },
      "outputs": [],
      "source": [
        "shutil.make_archive(\"img.zip\".replace('.zip', ''), 'zip', 'img')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3szA177u7fML"
      },
      "source": [
        "# Model for face segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz_qpOw99uib"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Reshape the images\n",
        "images = {}\n",
        "for key, value in np_img.items():\n",
        "    images[key] = value.reshape((960, 960, 3))\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array([images[key] for key in images.keys()])\n",
        "\n",
        "# Normalize the images\n",
        "X = X / 255.0\n",
        "\n",
        "# Generate synthetic masks\n",
        "def generate_synthetic_mask(image, threshold=0.5):\n",
        "    gray_image = np.mean(image, axis=-1)\n",
        "    mask = gray_image > threshold\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "Y = np.array([generate_synthetic_mask(image) for image in X])\n",
        "\n",
        "# Reshape Y to have a single channel\n",
        "Y = Y.reshape((Y.shape[0], Y.shape[1], Y.shape[2], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQCCC40k-uuG"
      },
      "outputs": [],
      "source": [
        "def unet_model(input_size=(960, 960, 3)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s28bJGxe-xb6"
      },
      "outputs": [],
      "source": [
        "# K-Fold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_no = 1\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    # Split data\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "\n",
        "    # Build model\n",
        "    model = unet_model()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(X_train, Y_train,\n",
        "                        epochs=50,\n",
        "                        batch_size=2,\n",
        "                        validation_data=(X_val, Y_val))\n",
        "\n",
        "    # Evaluate model\n",
        "    loss, accuracy = model.evaluate(X_val, Y_val)\n",
        "    val_losses.append(loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Fold {fold_no}: Validation Loss: {loss}, Validation Accuracy: {accuracy}\")\n",
        "    fold_no += 1\n",
        "\n",
        "print(f\"Average Validation Loss: {np.mean(val_losses)}, Average Validation Accuracy: {np.mean(val_accuracies)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG8yfEhcGNcR"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    image = image / 255.0\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    return image\n",
        "\n",
        "def postprocess_mask(mask, threshold=0.5):\n",
        "    mask = mask.squeeze()  # Remove batch dimension\n",
        "    mask = mask > threshold  # Apply threshold\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "# Example: Predict on a new image\n",
        "new_image = images['turq_marilyn']  # Replace with new image as needed\n",
        "preprocessed_image = preprocess_image(new_image)\n",
        "predicted_mask = model.predict(preprocessed_image)\n",
        "postprocessed_mask = postprocess_mask(predicted_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Yr3GQboGQHI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def overlay_mask_on_image(image, mask, color=(0, 255, 0), alpha=0.5):\n",
        "    \"\"\"Overlay the mask on the image with a given color and transparency.\"\"\"\n",
        "    overlay = image.copy()\n",
        "    for c in range(3):\n",
        "        overlay[:, :, c] = np.where(mask == 1, color[c], overlay[:, :, c])\n",
        "    return cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
        "\n",
        "# Overlay the mask on the original image\n",
        "colored_mask = overlay_mask_on_image(new_image, postprocessed_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQMOMfQzGSfa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_images(original, mask, overlay):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title('Original Image')\n",
        "    plt.imshow(original)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title('Predicted Mask')\n",
        "    plt.imshow(mask)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title('Overlay')\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Display the original image, the mask, and the overlay\n",
        "display_images(new_image, postprocessed_mask, colored_mask)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWjZnwD6Z6t5Xh1qDOU3nf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}